{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.980884139401\n",
      "Epoch 100, Loss: 0.0005045594603809715\n",
      "Epoch 200, Loss: 5.160036868090747e-07\n",
      "Epoch 300, Loss: 6.827768543094441e-10\n",
      "Epoch 400, Loss: 9.594638115615289e-13\n",
      "Epoch 500, Loss: 1.3629372898843925e-15\n",
      "Epoch 600, Loss: 1.939014718070554e-18\n",
      "Epoch 700, Loss: 2.7586962643200962e-21\n",
      "Epoch 800, Loss: 3.924380744815483e-24\n",
      "Epoch 900, Loss: 5.5868831829822894e-27\n",
      "Predictions: [1, 0]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class LinearRegressionTextClassifier:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = {}\n",
    "        self.bias = 0\n",
    "        self.vocab = set()\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Convert text to lowercase and split into words.\"\"\"\n",
    "        return re.findall(r'\\b[a-z]+\\b', text.lower())\n",
    "\n",
    "    def vectorize(self, text):\n",
    "        \"\"\"Convert text into a feature vector (Bag of Words).\"\"\"\n",
    "        dict1 = {}\n",
    "        words = self.preprocess(text)\n",
    "        # for word in self.vocab:\n",
    "        #     dict1[word] = words.count(word)\n",
    "        dict1 = Counter(words)\n",
    "        return dict1\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        \"\"\"Create a vocabulary from the training data.\"\"\"\n",
    "        for text in texts:\n",
    "            words = self.preprocess(text)\n",
    "            self.vocab.update(words)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Train the model using gradient descent.\"\"\"\n",
    "        self.build_vocab(X_train)\n",
    "\n",
    "        # Initialize weights for each word in the vocabulary\n",
    "        for word in self.vocab:\n",
    "            self.weights[word] = 0.0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "\n",
    "            for text, y in zip(X_train, y_train):\n",
    "                features = self.vectorize(text)\n",
    "                y_pred = self.bias  # Start with bias\n",
    "\n",
    "                # Compute weighted sum\n",
    "                for word, count in features.items():\n",
    "                    y_pred += self.weights[word] * count\n",
    "\n",
    "                # Compute error\n",
    "                error = y_pred - y\n",
    "                total_loss += error ** 2\n",
    "\n",
    "                # Update weights using gradient descent\n",
    "                for word, count in features.items():\n",
    "                    self.weights[word] -= self.learning_rate * error * count\n",
    "\n",
    "                # Update bias\n",
    "                self.bias -= self.learning_rate * error\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict the class (rounded regression output).\"\"\"\n",
    "        predictions = []\n",
    "        for text in X_test:\n",
    "            features = self.vectorize(text)\n",
    "            y_pred = self.bias\n",
    "\n",
    "            for word, count in features.items():\n",
    "                y_pred += self.weights.get(word, 0) * count  # Default 0 if word not seen\n",
    "\n",
    "            predictions.append(round(y_pred))  # Convert to class label\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Example Dataset (Text -> Binary Classification)\n",
    "X_train = [\"this is technology news\", \"latest AI model released\", \"new pet food launched\", \"dog health tips\"]\n",
    "y_train = [1, 1, 0, 0]  # 1 = Tech, 0 = Pet\n",
    "\n",
    "X_test = [\"AI is changing the world\", \"best dog food brands\"]\n",
    "\n",
    "# Train and Predict\n",
    "model = LinearRegressionTextClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the math:\n",
    "\n",
    "First, our prediction is computed as:\n",
    "\n",
    "ŷ = bias + Σ(weight_i * count_i) for each word i\n",
    "This is like the wx + b from simple linear regression, but now w is a vector of weights for each word\n",
    "\n",
    "\n",
    "We use Mean Squared Error loss:\n",
    "\n",
    "L = (ŷ - y)²\n",
    "\n",
    "\n",
    "For each weight w_i corresponding to word i:\n",
    "\n",
    "∂L/∂w_i = 2(ŷ - y) * ∂(ŷ)/∂w_i\n",
    "∂(ŷ)/∂w_i = count_i (how many times word i appears)\n",
    "Therefore: ∂L/∂w_i = 2(ŷ - y) * count_i\n",
    "In code: error * count (note: the 2 is absorbed into learning rate)\n",
    "\n",
    "\n",
    "For bias:\n",
    "\n",
    "∂L/∂b = 2(ŷ - y) * ∂(ŷ)/∂b\n",
    "∂(ŷ)/∂b = 1\n",
    "Therefore: ∂L/∂b = 2(ŷ - y)\n",
    "In code: error\n",
    "\n",
    "\n",
    "\n",
    "The intuition:\n",
    "\n",
    "Words that appear more frequently (higher count) have a larger impact on the gradient\n",
    "If a word appears in a misclassified example, its weight gets adjusted more if it appeared multiple times\n",
    "The error term (ŷ - y) determines the direction of the update\n",
    "If prediction is too high (error > 0), weights decrease\n",
    "If prediction is too low (error < 0), weights increase\n",
    "\n",
    "This is essentially doing linear regression but with a high-dimensional sparse feature vector (bag of words) instead of a single feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['tech', 'pet']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class TreeNode:\n",
    "    \"\"\"A node in the decision tree.\"\"\"\n",
    "    def __init__(self, word=None, left=None, right=None, label=None):\n",
    "        self.word = word  # Word used for splitting\n",
    "        self.left = left  # Left subtree\n",
    "        self.right = right  # Right subtree\n",
    "        self.label = label  # Class label (if leaf node)\n",
    "\n",
    "class DecisionTreeTextClassifier:\n",
    "    def __init__(self, min_samples=1, max_depth=10):\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.vocab = set()\n",
    "        self.root = None\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Tokenizes and normalizes text.\"\"\"\n",
    "        return re.findall(r'\\b[a-z]+\\b', text.lower())\n",
    "\n",
    "    def vectorize(self, text):\n",
    "        \"\"\"Converts text into a bag-of-words dictionary.\"\"\"\n",
    "        words = self.preprocess(text)\n",
    "        return {word: words.count(word) for word in self.vocab}\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        \"\"\"Builds a vocabulary from training texts.\"\"\"\n",
    "        for text in texts:\n",
    "            self.vocab.update(self.preprocess(text))\n",
    "\n",
    "    def gini_impurity(self, labels):\n",
    "        \"\"\"Calculates Gini impurity for a set of labels.\"\"\"\n",
    "        total = len(labels)\n",
    "        if total == 0:\n",
    "            return 0\n",
    "        counts = Counter(labels)\n",
    "        probs = [count / total for count in counts.values()]\n",
    "        return 1 - sum(p**2 for p in probs)\n",
    "\n",
    "    def best_split(self, texts, labels):\n",
    "        \"\"\"Finds the best word to split on by minimizing Gini impurity.\"\"\"\n",
    "        best_word, best_score, best_groups = None, float('inf'), None\n",
    "\n",
    "        for word in self.vocab:\n",
    "            left_texts, left_labels, right_texts, right_labels = [], [], [], []\n",
    "\n",
    "            for text, label in zip(texts, labels):\n",
    "                if word in text:\n",
    "                    left_texts.append(text)\n",
    "                    left_labels.append(label)\n",
    "                else:\n",
    "                    right_texts.append(text)\n",
    "                    right_labels.append(label)\n",
    "\n",
    "            gini = (len(left_labels) * self.gini_impurity(left_labels) +\n",
    "                    len(right_labels) * self.gini_impurity(right_labels)) / len(labels)\n",
    "\n",
    "            if gini < best_score:\n",
    "                best_word, best_score, best_groups = word, gini, (left_texts, left_labels, right_texts, right_labels)\n",
    "\n",
    "        return best_word, best_groups\n",
    "\n",
    "    def build_tree(self, texts, labels, depth=0):\n",
    "        \"\"\"Recursively builds the decision tree.\"\"\"\n",
    "        if len(set(labels)) == 1 or len(labels) < self.min_samples or depth >= self.max_depth:\n",
    "            return TreeNode(label=Counter(labels).most_common(1)[0][0])\n",
    "\n",
    "        word, (left_texts, left_labels, right_texts, right_labels) = self.best_split(texts, labels)\n",
    "\n",
    "        if not word or len(left_labels) == 0 or len(right_labels) == 0:\n",
    "            return TreeNode(label=Counter(labels).most_common(1)[0][0])\n",
    "\n",
    "        left = self.build_tree(left_texts, left_labels, depth + 1)\n",
    "        right = self.build_tree(right_texts, right_labels, depth + 1)\n",
    "        return TreeNode(word=word, left=left, right=right)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Trains the decision tree model.\"\"\"\n",
    "        self.build_vocab(X_train)\n",
    "        X_train = [self.preprocess(text) for text in X_train]\n",
    "        self.root = self.build_tree(X_train, y_train)\n",
    "\n",
    "    def predict_one(self, text):\n",
    "        \"\"\"Predicts the class of a single text by traversing the tree.\"\"\"\n",
    "        node = self.root\n",
    "        words = set(self.preprocess(text))\n",
    "\n",
    "        while node.word:\n",
    "            node = node.left if node.word in words else node.right\n",
    "\n",
    "        return node.label\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predicts class labels for a list of texts.\"\"\"\n",
    "        return [self.predict_one(text) for text in X_test]\n",
    "\n",
    "\n",
    "# Example Dataset\n",
    "X_train = [\"AI revolution in technology\", \"Latest machine learning update\",\n",
    "           \"Dog food and health\", \"Best pet care tips\"]\n",
    "y_train = [\"tech\", \"tech\", \"pet\", \"pet\"]\n",
    "\n",
    "X_test = [\"AI model advancements\", \"Healthy dog food choices\"]\n",
    "\n",
    "# Train and Predict\n",
    "tree_model = DecisionTreeTextClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "predictions = tree_model.predict(X_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def gini_impurity(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        impurity = 1\n",
    "        for count in counts:\n",
    "            prob = count / len(y)\n",
    "            impurity -= prob ** 2\n",
    "        return impurity\n",
    "    \n",
    "    def split_data(self, X, y, feature_idx, threshold):\n",
    "        left_mask = X[:, feature_idx] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "        return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    def find_best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        for feature_idx in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                X_left, X_right, y_left, y_right = self.split_data(X, y, feature_idx, threshold)\n",
    "                \n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gini = (len(y_left) * self.gini_impurity(y_left) + \n",
    "                       len(y_right) * self.gini_impurity(y_right)) / len(y)\n",
    "                \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature_idx\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Implement TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "Your task is to implement a function that computes the TF-IDF scores for a query against a given corpus of documents.\n",
    "\n",
    "Function Signature\n",
    "Write a function compute_tf_idf(corpus, query) that takes the following inputs:\n",
    "\n",
    "corpus: A list of documents, where each document is a list of words.\n",
    "query: A list of words for which you want to compute the TF-IDF scores.\n",
    "Output\n",
    "The function should return a list of lists containing the TF-IDF scores for the query words in each document, rounded to five decimal places.\n",
    "\n",
    "Important Considerations\n",
    "Handling Division by Zero:\n",
    "When implementing the Inverse Document Frequency (IDF) calculation, you must account for cases where a term does not appear in any document (df = 0). This can lead to division by zero in the standard IDF formula. Add smoothing (e.g., adding 1 to both numerator and denominator) to avoid such errors.\n",
    "\n",
    "Empty Corpus:\n",
    "Ensure your implementation gracefully handles the case of an empty corpus. If no documents are provided, your function should either raise an appropriate error or return an empty result. This will ensure the program remains robust and predictable.\n",
    "\n",
    "Edge Cases:\n",
    "\n",
    "Query terms not present in the corpus.\n",
    "Documents with no words.\n",
    "Extremely large or small values for term frequencies or document frequencies.\n",
    "By addressing these considerations, your implementation will be robust and handle real-world scenarios effectively.\n",
    "\n",
    "Example:\n",
    "Input:\n",
    "corpus = [\n",
    "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n",
    "    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n",
    "]\n",
    "query = [\"cat\"]\n",
    "\n",
    "print(compute_tf_idf(corpus, query))\n",
    "Output:\n",
    "[[0.21461], [0.25754], [0.0]]\n",
    "Reasoning:\n",
    "The TF-IDF scores for the word \"cat\" in each document are computed and rounded to five decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t•\tDocument Frequency (DF) counts how many documents contain a given term.\n",
    "\t•\tExample: If query = [\"cat\"], it appears in two documents, so df[\"cat\"] = 2.\n",
    "\n",
    "    \t•\tInverse Document Frequency (IDF) reduces the weight of words that appear frequently in many documents.\n",
    "\t•\tThe formula used is:\n",
    "\n",
    "IDF(t) = \\log\\left(\\frac{N+1}{DF(t) + 1}\\right) + 1\n",
    "\n",
    "\t•\tN = total number of documents\n",
    "\t•\tDF(t) = document frequency of term t\n",
    "\t•\tSmoothing: Adding 1 to prevent division by zero if a term is absent.\n",
    "\t•\tExample: If cat appears in 2 out of 3 documents,\n",
    "\n",
    "IDF(\\text{cat}) = \\log\\left(\\frac{3+1}{2+1}\\right) + 1 = \\log\\left(\\frac{4}{3}\\right) + 1 \\approx 1.2877\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✨ Summary\n",
    "\t1.\tTF measures how frequently a term appears in a document.\n",
    "\t2.\tIDF reduces the weight of common words across multiple documents.\n",
    "\t3.\tTF-IDF provides a balanced score to highlight important words.\n",
    "\t4.\tImplementation:\n",
    "\t•\tCount document frequency (DF)\n",
    "\t•\tCompute IDF with smoothing\n",
    "\t•\tCalculate TF-IDF for each document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf 是t , d的函数，idf是t的函数；tf(t, d); idf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df= {'cat': 2, 'the': 3}\n",
      "idf= {'cat': 1.2876820724517808, 'the': 1.0}\n",
      "[[0.21461367874196347, 0.3333333333333333], [0.2575364144903562, 0.4], [0.0, 0.3333333333333333]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def compute_tf_idf(corpus, query):\n",
    "    if not corpus:\n",
    "        return []\n",
    "\n",
    "    # Compute document frequency for each term in query\n",
    "    doc_count = len(corpus)\n",
    "    df = {}\n",
    "    # Iterate over each term in the query\n",
    "    for term in query:\n",
    "        count = 0  # Initialize count of documents containing the term\n",
    "\n",
    "        # Iterate over each document in the corpus\n",
    "        for doc in corpus:\n",
    "            if term in doc:  # Check if the term is in the document\n",
    "                count += 1  # Increment count if the term is found\n",
    "\n",
    "        df[term] = count  # Store the count in the df dictionary #  DF(t) Document frequency\n",
    "\n",
    "    print('df=',df)\n",
    "    # Compute IDF with smoothing\n",
    "    idf = {term: math.log((doc_count + 1) / (df[term] + 1)) + 1 for term in query}\n",
    "    print('idf=',idf)\n",
    "\n",
    "    tf_idf_scores = []\n",
    "\n",
    "    for doc in corpus:\n",
    "        term_counts = Counter(doc)\n",
    "        doc_length = len(doc)\n",
    "        scores = []  # Initialize an empty list to store TF-IDF scores\n",
    "\n",
    "        # Iterate over each term in the query\n",
    "        for term in query:\n",
    "            term_count = doc.count(term)  # Count occurrences of the term in the document\n",
    "            if term_count > 0:  # If term appears in the document\n",
    "                tf = term_count / doc_length  # Compute Term Frequency (TF) normalized by doc length\n",
    "                tf_idf = tf * idf[term]  # Multiply by IDF\n",
    "                scores.append(tf_idf)  \n",
    "            else:\n",
    "                scores.append(0.0)  # If term is not in document, append 0.0\n",
    "\n",
    "        tf_idf_scores.append(scores)\n",
    "\n",
    "    return tf_idf_scores\n",
    "\n",
    "# Example usage\n",
    "corpus = [\n",
    "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n",
    "    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n",
    "]\n",
    "query = [\"cat\", 'the']\n",
    "\n",
    "print(compute_tf_idf(corpus, query))  # Output: [[0.21461], [0.25754], [0.0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df= {'cat': 2, 'the': 3}\n",
      "idf= {'cat': 1.2876820724517808, 'the': 1.0}\n",
      "[[0.21461367874196347, 0.3333333333333333], [0.2575364144903562, 0.4], [0.0, 0.3333333333333333]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def compute_tf_idf(corpus, query):\n",
    "    if not corpus:\n",
    "        return []\n",
    "\n",
    "    # Compute document frequency for each term in query\n",
    "    doc_count = len(corpus)\n",
    "    df = {}\n",
    "    # Iterate over each term in the query\n",
    "    for term in query:\n",
    "        count = 0  # Initialize count of documents containing the term\n",
    "\n",
    "        # Iterate over each document in the corpus\n",
    "        for doc in corpus:\n",
    "            if term in doc:  # Check if the term is in the document\n",
    "                count += 1  # Increment count if the term is found\n",
    "\n",
    "        df[term] = count  # Store the count in the df dictionary #  DF(t) Document frequency\n",
    "\n",
    "    print('df=',df)\n",
    "    # Compute IDF with smoothing\n",
    "    idf = {term: math.log((doc_count + 1) / (df[term] + 1)) + 1 for term in query}\n",
    "    print('idf=',idf)\n",
    "\n",
    "    tf_idf_scores = []\n",
    "\n",
    "    for doc in corpus:\n",
    "        term_counts = Counter(doc)\n",
    "        doc_length = len(doc)\n",
    "        scores = []  # Initialize an empty list to store TF-IDF scores\n",
    "\n",
    "        # Iterate over each term in the query\n",
    "        for term in query:\n",
    "            term_count = term_counts.get(term,0)  # Count occurrences of the term in the document\n",
    "            if term_count > 0:  # If term appears in the document\n",
    "                tf = term_count / doc_length  # Compute Term Frequency (TF) normalized by doc length\n",
    "                tf_idf = tf * idf[term]  # Multiply by IDF\n",
    "                scores.append(tf_idf)  \n",
    "            else:\n",
    "                scores.append(0.0)  # If term is not in document, append 0.0\n",
    "\n",
    "        tf_idf_scores.append(scores)\n",
    "\n",
    "    return tf_idf_scores\n",
    "\n",
    "# Example usage\n",
    "corpus = [\n",
    "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n",
    "    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n",
    "]\n",
    "query = [\"cat\", 'the']\n",
    "\n",
    "print(compute_tf_idf(corpus, query))  # Output: [[0.21461], [0.25754], [0.0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21461], [0.25754], [0.0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_tf_idf(corpus, query):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF scores for a query against a corpus of documents using only NumPy.\n",
    "    The output TF-IDF scores retain five decimal places.\n",
    "    \"\"\"\n",
    "    vocab = sorted(set(word for document in corpus for word in document).union(query))\n",
    "    word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "    tf = np.zeros((len(corpus), len(vocab)))\n",
    "\n",
    "    for doc_idx, document in enumerate(corpus):\n",
    "        for word in document:\n",
    "            word_idx = word_to_index[word]\n",
    "            tf[doc_idx, word_idx] += 1\n",
    "        tf[doc_idx, :] /= len(document)\n",
    "\n",
    "    df = np.count_nonzero(tf > 0, axis=0)\n",
    "\n",
    "    num_docs = len(corpus)\n",
    "    idf = np.log((num_docs + 1) / (df + 1)) + 1\n",
    "\n",
    "    tf_idf = tf * idf\n",
    "\n",
    "    query_indices = [word_to_index[word] for word in query]\n",
    "    tf_idf_scores = tf_idf[:, query_indices]\n",
    "\n",
    "    tf_idf_scores = np.round(tf_idf_scores, 5)\n",
    "\n",
    "    return tf_idf_scores.tolist()\n",
    "\n",
    "corpus = [\n",
    "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n",
    "    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n",
    "]\n",
    "query = [\"cat\"]\n",
    "\n",
    "print(compute_tf_idf(corpus, query))  # Output: [[0.21461], [0.25754], [0.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class TFIDF:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = {}\n",
    "        self.idf_values = {}\n",
    "    \n",
    "    def fit(self, documents):\n",
    "        all_words = set()\n",
    "        for doc in documents:\n",
    "            words = doc.lower().split()\n",
    "            all_words.update(words)\n",
    "        \n",
    "        self.vocabulary = {word: idx for idx, word in enumerate(all_words)}\n",
    "        \n",
    "        # Calculate IDF\n",
    "        n_docs = len(documents)\n",
    "        for word in self.vocabulary:\n",
    "            doc_count = sum(1 for doc in documents if word in doc.lower().split())\n",
    "            self.idf_values[word] = math.log(n_docs / doc_count)\n",
    "    \n",
    "    def transform(self, documents):\n",
    "        tfidf_matrix = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            words = doc.lower().split()\n",
    "            word_count = Counter(words)\n",
    "            doc_length = len(words)\n",
    "            \n",
    "            tfidf_vector = np.zeros(len(self.vocabulary))\n",
    "            \n",
    "            for word, count in word_count.items():\n",
    "                if word in self.vocabulary:\n",
    "                    tf = count / doc_length\n",
    "                    idf = self.idf_values[word]\n",
    "                    idx = self.vocabulary[word]\n",
    "                    tfidf_vector[idx] = tf * idf\n",
    "            \n",
    "            tfidf_matrix.append(tfidf_vector)\n",
    "        \n",
    "        return np.array(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idf {'mat': 1.4054651081081644, 'the': 1.0, 'cat': 1.4054651081081644, 'on': 2.09861228866811, 'sat': 2.09861228866811, 'chased': 2.09861228866811, 'dog': 2.09861228866811, 'flew': 2.09861228866811, 'bird': 2.09861228866811, 'over': 2.09861228866811}\n",
      "df {'mat': 2, 'the': 3, 'cat': 2, 'on': 1, 'sat': 1, 'chased': 1, 'dog': 1, 'flew': 1, 'bird': 1, 'over': 1}\n",
      "[[0.23424418468469405, 0.3333333333333333], [0.2810930216216329, 0.4], [0, 0.3333333333333333]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def compute_tf_idf(corpus, query):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF scores for a query against a corpus of documents using only NumPy.\n",
    "    \"\"\"\n",
    "    df = {}\n",
    "    idf = {}\n",
    "\n",
    "    for doc in corpus:\n",
    "        unique_terms = set(doc)\n",
    "        for term in unique_terms:\n",
    "            if term not in df:\n",
    "                df[term]=1\n",
    "            else:\n",
    "                df[term]+=1\n",
    "\n",
    "    for term in df:\n",
    "        idf[term] = np.log(len(corpus)/df[term] ) + 1\n",
    "    print('idf',idf)\n",
    "    print('df',df)\n",
    "\n",
    "    res = []\n",
    "    \n",
    "    for doc in corpus:\n",
    "        scores = []\n",
    "        term_counts = Counter(doc)\n",
    "        doc_length = len(doc)\n",
    "\n",
    "        for q in query:\n",
    "            tf = term_counts.get(q,0)/doc_length\n",
    "            if tf>0:\n",
    "                tfidf = tf * idf[q]\n",
    "            else:\n",
    "                tfidf = 0\n",
    "            scores.append(tfidf)\n",
    "        res.append(scores)\n",
    "    return res\n",
    "            \n",
    "\n",
    "\n",
    "corpus = [\n",
    "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n",
    "    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n",
    "]\n",
    "query = [\"cat\", \"the\"]\n",
    "\n",
    "print(compute_tf_idf(corpus, query))  # Output: [[0.21461], [0.25754], [0.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

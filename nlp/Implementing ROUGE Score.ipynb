{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5846b1",
   "metadata": {},
   "source": [
    "Implementing ROUGE Score\n",
    "Medium\n",
    "Machine Learning\n",
    "\n",
    "Implement the ROUGE-1 (Recall-Oriented Understudy for Gisting Evaluation) score to evaluate the quality of a generated summary by comparing it to a reference summary. ROUGE-1 focuses on unigram (single word) overlaps between the candidate and reference texts. Your task is to write a function that computes the ROUGE-1 recall, precision, and F1 score based on the number of overlapping unigrams.\n",
    "\n",
    "Example:\n",
    "Input:\n",
    "rouge_1_score('the cat sat on the mat', 'the cat is on the mat')\n",
    "Output:\n",
    "{'precision': 0.8333333333333334, 'recall': 0.8333333333333334, 'f1': 0.8333333333333334}\n",
    "Reasoning:\n",
    "The reference text 'the cat sat on the mat' has 6 tokens, and the candidate text 'the cat is on the mat' has 6 tokens. The overlapping words are: 'the' (appears 2 times in reference, 2 times in candidate, so min(2,2)=2 overlap), 'cat' (1,1 → 1 overlap), 'on' (1,1 → 1 overlap), and 'mat' (1,1 → 1 overlap). Total overlap = 2+1+1+1 = 5. Precision = 5/6 ≈ 0.833 (5 overlapping words out of 6 candidate words). Recall = 5/6 ≈ 0.833 (5 overlapping words out of 6 reference words). F1 = 2×(0.833×0.833)/(0.833+0.833) = 0.833 since precision equals recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3acb306",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def rouge_1_score(reference: str, candidate: str):\n",
    "    # lowercase + whitespace tokenization (simple ROUGE-1)\n",
    "    ref_tokens = reference.lower().split()\n",
    "    cand_tokens = candidate.lower().split()\n",
    "\n",
    "    if len(ref_tokens) == 0 and len(cand_tokens) == 0:\n",
    "        return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
    "\n",
    "    ref_counts = Counter(ref_tokens)\n",
    "    cand_counts = Counter(cand_tokens)\n",
    "\n",
    "    # overlap counts = sum of min(ref[w], cand[w]) for all shared unigrams\n",
    "    overlap = 0\n",
    "    for word in ref_counts:\n",
    "        if word in cand_counts:\n",
    "            # Step 2. Add the minimum count (so duplicates are handled correctly)\n",
    "            overlap += min(ref_counts[word], cand_counts[word])\n",
    "\n",
    "    precision = overlap / len(cand_tokens) if cand_tokens else 0.0\n",
    "    recall    = overlap / len(ref_tokens)  if ref_tokens  else 0.0\n",
    "    f1 = 0.0 if precision + recall == 0 else 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Example\n",
    "print(rouge_1_score('the cat sat on the mat', 'the cat is on the mat'))\n",
    "# {'precision': 0.8333333333333334, 'recall': 0.8333333333333334, 'f1': 0.8333333333333334}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

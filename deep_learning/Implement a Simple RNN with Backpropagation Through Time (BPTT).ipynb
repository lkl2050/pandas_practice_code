{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Implement a Simple RNN with Backpropagation Through Time (BPTT)\n",
    "Your task is to implement a simple Recurrent Neural Network (RNN) and backpropagation through time (BPTT) to learn from sequential data. The RNN will process input sequences, update hidden states, and perform backpropagation to adjust weights based on the error gradient.\n",
    "\n",
    "Write a class SimpleRNN with the following methods:\n",
    "\n",
    "__init__(self, input_size, hidden_size, output_size): Initializes the RNN with random weights and zero biases.\n",
    "forward(self, x): Processes a sequence of inputs and returns the hidden states and output.\n",
    "backward(self, x, y, learning_rate): Performs backpropagation through time (BPTT) to adjust the weights based on the loss.\n",
    "In this task, the RNN will be trained on sequence prediction, where the network will learn to predict the next item in a sequence. You should use 1/2 * Mean Squared Error (MSE) as the loss function and make sure to aggregate the losses at each time step by summing.\n",
    "\n",
    "Example:\n",
    "Input:\n",
    "import numpy as np\n",
    "    input_sequence = np.array([[1.0], [2.0], [3.0], [4.0]])\n",
    "    expected_output = np.array([[2.0], [3.0], [4.0], [5.0]])\n",
    "    # Initialize RNN\n",
    "    rnn = SimpleRNN(input_size=1, hidden_size=5, output_size=1)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = rnn.forward(input_sequence)\n",
    "    \n",
    "    # Backward pass\n",
    "    rnn.backward(input_sequence, expected_output, learning_rate=0.01)\n",
    "    \n",
    "    print(output)\n",
    "    \n",
    "    # The output should show the RNN predictions for each step of the input sequence.\n",
    "Output:\n",
    "[[x1], [x2], [x3], [x4]]\n",
    "Reasoning:\n",
    "The RNN processes the input sequence [1.0, 2.0, 3.0, 4.0] and predicts the next item in the sequence at each step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleRNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_xh = np.random.randn(hidden_size, input_size) * 0.01\n",
    "        self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "        self.W_hy = np.random.randn(output_size, hidden_size) * 0.01\n",
    "        self.b_h = np.zeros((hidden_size, 1))\n",
    "        self.b_y = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = np.zeros((self.hidden_size, 1))  # Initialize hidden state\n",
    "        outputs = []\n",
    "        self.last_inputs = []\n",
    "        self.last_hiddens = [h]\n",
    "\n",
    "        for t in range(len(x)):\n",
    "            self.last_inputs.append(x[t].reshape(-1, 1))\n",
    "            h = np.tanh(np.dot(self.W_xh, self.last_inputs[t]) + np.dot(self.W_hh, h) + self.b_h)\n",
    "            y = np.dot(self.W_hy, h) + self.b_y\n",
    "            outputs.append(y)\n",
    "            self.last_hiddens.append(h)\n",
    "\n",
    "        self.last_outputs = outputs\n",
    "        return np.array(outputs)\n",
    "\n",
    "    def backward(self, x, y, learning_rate):\n",
    "        dW_xh = np.zeros_like(self.W_xh)\n",
    "        dW_hh = np.zeros_like(self.W_hh)\n",
    "        dW_hy = np.zeros_like(self.W_hy)\n",
    "        db_h = np.zeros_like(self.b_h)\n",
    "        db_y = np.zeros_like(self.b_y)\n",
    "\n",
    "        dh_next = np.zeros((self.hidden_size, 1))\n",
    "\n",
    "        for t in reversed(range(len(x))):\n",
    "            dy = self.last_outputs[t] - y[t].reshape(-1, 1)  # (Predicted - Actual)\n",
    "            dW_hy += np.dot(dy, self.last_hiddens[t+1].T)\n",
    "            db_y += dy\n",
    "\n",
    "            dh = np.dot(self.W_hy.T, dy) + dh_next\n",
    "            dh_raw = (1 - self.last_hiddens[t+1] ** 2) * dh  # Derivative of tanh\n",
    "\n",
    "            dW_xh += np.dot(dh_raw, self.last_inputs[t].T)\n",
    "            dW_hh += np.dot(dh_raw, self.last_hiddens[t].T)\n",
    "            db_h += dh_raw\n",
    "\n",
    "            dh_next = np.dot(self.W_hh.T, dh_raw)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.W_xh -= learning_rate * dW_xh\n",
    "        self.W_hh -= learning_rate * dW_hh\n",
    "        self.W_hy -= learning_rate * dW_hy\n",
    "        self.b_h -= learning_rate * db_h\n",
    "        self.b_y -= learning_rate * db_y\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

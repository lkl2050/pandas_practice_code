{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d68797b",
   "metadata": {},
   "source": [
    "Implement a function that creates a simple residual block using NumPy. The block should take a 1D input array, process it through two weight layers (using matrix multiplication), apply ReLU activations, and add the original input via a shortcut connection before a final ReLU activation.\n",
    "\n",
    "Example:\n",
    "Input:\n",
    "x = np.array([1.0, 2.0]), w1 = np.array([[1.0, 0.0], [0.0, 1.0]]), w2 = np.array([[0.5, 0.0], [0.0, 0.5]])\n",
    "Output:\n",
    "[1.5, 3.0]\n",
    "Reasoning:\n",
    "The input x is [1.0, 2.0]. First, compute w1 @ x = [1.0, 2.0], apply ReLU to get [1.0, 2.0]. Then, compute w2 @ [1.0, 2.0] = [0.5, 1.0]. Add the shortcut x to get [0.5 + 1.0, 1.0 + 2.0] = [1.5, 3.0]. Final ReLU gives [1.5, 3.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x: np.ndarray) -> np.ndarray:\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def residual_block(x: np.ndarray, w1: np.ndarray, w2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple residual block:\n",
    "    out = ReLU( (w2 @ ReLU(w1 @ x)) + x )\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Input 1D array of shape (n,)\n",
    "    w1 : np.ndarray\n",
    "        First weight matrix of shape (m, n)\n",
    "    w2 : np.ndarray\n",
    "        Second weight matrix of shape (n, m)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Output after residual block, shape (n,)\n",
    "    \"\"\"\n",
    "    # First layer + ReLU\n",
    "    h1 = relu(w1 @ x)\n",
    "    # Second layer\n",
    "    h2 = w2 @ h1\n",
    "    # Add shortcut\n",
    "    out = h2 + x\n",
    "    # Final ReLU\n",
    "    return relu(out)\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "    x = np.array([1.0, 2.0])\n",
    "    w1 = np.array([[1.0, 0.0],\n",
    "                   [0.0, 1.0]])\n",
    "    w2 = np.array([[0.5, 0.0],\n",
    "                   [0.0, 0.5]])\n",
    "    print(residual_block(x, w1, w2))  # [1.5, 3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def residual_block(x: torch.Tensor, w1: torch.Tensor, w2: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Simple residual block:\n",
    "    out = ReLU( (w2 @ ReLU(w1 @ x)) + x )\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Input 1D tensor of shape (n,)\n",
    "    w1 : torch.Tensor\n",
    "        First weight matrix of shape (m, n)\n",
    "    w2 : torch.Tensor\n",
    "        Second weight matrix of shape (n, m)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Output after residual block, shape (n,)\n",
    "    \"\"\"\n",
    "    # First layer + ReLU\n",
    "    h1 = F.relu(w1 @ x)\n",
    "    # Second layer\n",
    "    h2 = w2 @ h1\n",
    "    # Add shortcut\n",
    "    out = h2 + x\n",
    "    # Final ReLU\n",
    "    return F.relu(out)\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.tensor([1.0, 2.0])\n",
    "    w1 = torch.tensor([[1.0, 0.0],\n",
    "                       [0.0, 1.0]])\n",
    "    w2 = torch.tensor([[0.5, 0.0],\n",
    "                       [0.0, 0.5]])\n",
    "    print(residual_block(x, w1, w2))  # tensor([1.5000, 3.0000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
